---
title: 'Part 2: Ordinary differential equations'
subtitle: "E. Bifurcation"
author: "Mingyang Lu"
date: "10/29/2021"
output:
  html_document:
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Intro

Let us continue our discussion on the circuit of one self-activating gene (Equations (7) - (8) in Part 2A). When we vary the values of $k$, as we learned from Part 2D, the circuit can have either one steady state (monostable) or three steady states (bistable as there are two stable states). To get a more complete picture of the system, we consider $k$ as a control parameter, and plot the curve of steady states $X_s$ as the function of $k$. This is called 1-dimensional bifurcation diagram. Let us discuss how we obtain such as curve numerically. We consider the following rate equation with $X$ as the state variable and $k$ as the control parameter.

\begin{equation}
\frac{dX}{dt} = f(X,k) = 10 + 45\frac{X^4}{X^4+200^4} - kX \tag{1}
\end{equation}

``` {r}
derivs_k <- function(X, k) {
  return(10 + 45 * (1- 1/(1+(X/200)**4)) - k*X)
}
```

# Method 1: (direct method) find all roots

The most straightforward way is to uniformly sample $k$ values and, for each $k$, identify all roots $X_s$ for $f(X,k)=0$. The following shows an implementation of such method using an R package rootSolve. We also check stability of steady states according to $\frac{df}{dX}$. It works very well for this example. However, it may fail in some situations, as finding all roots for a nonlinear function s not guaranteed. Compared to other methods, this method should be slower but more stable. The implementation below uses a for loop, which clearly shows how it works. One can also use lapply instead of a for loop. 

``` {r}
library(rootSolve)
dx = 0.1  # used to estimate the derivatives of f(X) near the steady states
k_all = seq(0.1,0.2, by = 0.001)    # all k values to be sampled
results = matrix(0, nrow = length(k_all)*3, ncol = 3)  # Define a sufficiently large matrix to save k & steady-state X
ind = 0
for(k in k_all) {
  roots = uniroot.all(derivs_k, k = k, interval = c(0, 800)) # find all roots 
  for(x in roots){
    ind = ind + 1
    if(sign(derivs_k(X = x+dx, k = k)) < 0) { # df/dX < 0, stable
      stability = 1
    }else{
      stability = 2
    }
    results[ind,] = c(k, x, stability) 
  }
}
results = results[1:ind,]

plot(results[,1], results[,2], type = "p", pch = 1, cex = 0.3, col= results[,3],
    xlab=parse(text="k (Minute^{-1})"), ylab="Xs (nM)", xlim=c(0.09, 0.21), ylim=c(0,600)) 
legend("topright", inset=0.02, legend = c("Stable", "Unstable"), col=1:2, lty=1, cex=0.8)
```

The bifurcation curve clearly shows how the dynamical behavior of the circuit changes with respect to the changes in $k$. There are two turning points of the bifurcation curve. The first one is at around $k = 0.125$, where one of the stable steady states and the unstable steady state has very close $X$ values. The second one is at around $k = 0.170$. These two points are called bifurcation points. The system is monostable when $k$ is smaller than the $k$ value of the first bifurcation point. In this regime, the $X$ steady state level is relatively high. When $k$ is between the $k$ values of the two bifurcation points, the system is bistable, with two stable steady states of both high and low $X$ levels. When $k$ is higher than the $k$ value of the second bifurcation point, the system becomes monostable again, with one stable steady state of relatively low $X$ level. This type of bifurcation is called saddle-node bifurcation.

# Method 2: Get bifurcation curve by simulations

The second method does not require to solve all roots of $f(X,k)$. Instead, we will utilize the properties of steady states to map all steady states for different $k$. We will start with $k = 0.1$ and simulate the ODE using a random initial condition. Once we reach the steady state, we will record $k$ and $X$. Then, we will increase $k$ by a small step $\Delta k$ and simulate the ODE again with the previous steady state as the initial condition. We will repeat the process until we reach a bifurcation point. This can be determined when the new steady state $X_s$ is very different (compared to previous changes) or nonexistent (that could happen when we compute the unstable state, see below) from the steady state of the previous $k$. (Please also note that this approach should work well for the saddle-node bifurcation in this example, but may not work well for other types of bifurcation.) At this point, we will start another cycle by decreasing $k$ instead. To reach the unstable steady states, we will simulate a modified ODE:

$$ \frac{dX}{dt} = -f(X,k) \tag{2}$$
This trick allows us to obtain the unstable steady state from ODE simulations, as the unstable state becomes stable state using Equation (2). We will repeat the same procedure, until we reach the maximum $k = 0.2$. Below shows the implementation.

The pseudocode of this algorithm is:

Start:

* Initial $k = k_1 = 0.1$.

* A random initial condition of $X = X_0$.

* Initial direction to sample $k$: increasing ($d_1 = 1$)

* $i = 1$

While $k_i < 0.2$:  (An iteration)

1. From the initial condition $X_{i-1}$, simulate $\frac{dX}{dt} = d_i f(X, k_i)$ until a stable steady state $X_i$ is reached.

2. Record $k_i$ and $X_i$.

3. If $i \ne 1$ AND $X_i$ is very different from $X_{i-1}$:

   $d_{i+1} = -d_i$ (A bifurcation point is reached, reverse direction to sample $k$).
   
4. $k_{i+1} = k_i + d_{i+1} \Delta k$. (Next $k$)

5. $i = i + 1$

In Step 1, when sampling along the reverse direction of $k$, $\frac{dX}{dt} = - f(X, k)$ will converge to an unstable steady state in the original ODE. 

```{r}
# Define the derivative function
# k: control parameter; d: 1 - stable steady state; 2 - unstable steady state
derivs_k_deSolve <- function(t, X, params) {
  with(as.list(c(X, params)), {
    return(list(d*(10 + 45 * (1 - 1 / (1 + (X / 200)^4)) - k * X)))
})
}

# Algorithm parameters
gap = 100.0     # the stop criterion for a bifurcation point: when Delta X changes larger than the threshold value (gap) when k increases a little, the system undergoes catastrophe.
t_max = 1000.0   # Maximum ODE simulation time
dk = 0.001 # k step size 
dX = 1 # make a small step in X to estimate df/dX, a small step to perturb X0

# Initialize parameters
k = 0.1
X0 = runif(1, 100, 600)  # Random initial condition of X
d = 1
ind = 1 # Record the index of steady states

# Initialize results storage
results = matrix(data = NA, nrow = 1000, ncol = 3)

while (k < 0.2) {
  # Simulate until a stable steady state is reached
  Xi = runsteady(y=X0, time = c(0, t_max), func=derivs_k_deSolve, parms=c(k=k, d=d))$y 

  # Check for bifurcation point, switch the sampling direction of k.
  if (ind > 1 && abs(Xi - X0) > gap) {
    d = -d
    # Update k 
    k = k + d * dk
    # Update X0, with slight perturbation along the same direction from X0 to Xi in the current step
    X0 = X0 + dX * sign(Xi-X0)
  } else{
    # Determine stabiity of the steady state
    f_x_plus_dx = derivs_k_deSolve(t = 0, X = Xi+dX, params = c(k = k, d = 1))[[1]]
    if(sign(f_x_plus_dx) < 0) { # df/dX < 0, stable
      stability = 1
    }else{
      stability = 2
    }
    
    # record the steady state
    results[ind,] = c(k, Xi, stability) 
    
    # Update k and the initial X for the next iteration
    k = k + d*dk
    X0 = Xi
    # Update iteration counter
    ind = ind + 1
  }

}

# Plot the bifurcation diagram
plot(results[,1], results[,2], pch = 1, cex = 0.3, col = results[,3],
     xlab=parse(text="k (Minute^{-1})"), ylab="Xs (nM)", xlim=c(0.09, 0.21), ylim=c(0,600))
```

The implementation works well to obtain all steady states of any $k$. However, like many numerical methods, it is challenging to devise a robust function to find bifurcation diagrams for a generic system. In particular, the choice of the numerical parameters (gap, t_max, dX) would affect the performance of the method. (Try to adjust these parameters, and evaluate the outcomes.)

# Method 3: numerical continuation

The most widely used and generally applicable method is numerical continuation. Our goal is to find $X(k)$ to satisfy 

$$ f(X, k) = 0 $$
Take partial derivatives with respect to $X$ and $k$, we get

$$ \frac{\partial f}{\partial X}\Delta X + \frac{\partial f}{\partial k}\Delta k = 0 $$
Thus,

$$ \frac{dX}{dk} \equiv h(X,k) = -\frac{\frac{\partial f}{\partial k}}{\frac{\partial f}{\partial X}} \tag{2}$$
The expression is defined as a function h, which will be used later. Therefore, starting from a steady state $X$ for a specific $k$, we can obtain the slope of the bifurcation curve $\frac{dX}{dk}$ from Equation (2). This allows us to find the initial guess of the next ($k$, $X$) point. 

\begin{equation}
\begin{cases} k_{new} = k + \Delta k \\
              X_{new} = X +  \frac{dX}{dk}\Delta k  \end{cases} \tag{3}
\end{equation}

## Newton's method

We can then use a correction method, such as Newton's method, to find the nearby solution. For Newton's method, we solve $f(X) = 0$ starting from an initial guess at $X_0$. 

$$f(X_0 + \Delta X) = f(X_0) + f'(X_0)\Delta X = 0$$

Thus,

$$\Delta X = - \frac{f(X_0)}{f'(X_0)} \tag{4}$$
Numerically, we perform the following calculation iteratively:

$$ X_{n+1} = X_n - \frac{f(X_n)}{f'(X_n)} $$
, until $|f(X_{n+1})|<\epsilon$, where $\epsilon$ is a small constant. Below shows the implementation of Newton's method for the current system (the find_root_Newton function).  The function is used to find roots for different initial conditions and control parameters.

``` {r}
dfdX <- function(X, k){    
    x_frac = (X/200)**4
    return( 180 /X * x_frac/(1+x_frac)**2 - k)
}

# Implementation of the Newton's method to find a root of func
find_root_Newton <- function(X, func, dfunc, X_range, error = 10^-3, ...) {
  #X: Initial guess of X
  #func: function f(X,...)
  #dfunc: df/dX
  #X_range: lower and upper limits of root X. If X is outside of the range, the algorithm stops.
  f = func(X, ...)
  while(abs(f) > error){
    X = X - f/dfunc(X, ...)
    if((X-X_range[1])*(X-X_range[2]) > 0) break  # Check if X is in within X_range; 
    # This would avoid potential infinite loop; When this occurs, the Newton's method doesn't converge.
    f = func(X, ...)
  }
  return(X)
}

find_root_Newton(500, derivs_k, dfdX, c(0, 800), k = 0.1)   # monostable, one root
find_root_Newton(500, derivs_k, dfdX, c(0, 800), k = 0.15)   # bistable, first root near 500
find_root_Newton(100, derivs_k, dfdX, c(0, 800), k = 0.15)  # another root near 100
find_root_Newton(150, derivs_k, dfdX, c(0, 800), k = 0.15)  # the last root (unstable) near 150
```
## An implementation of the continuation method

Now, we implement the numerical continuation method by uniformly varying $k$. 

``` {r}
# Define the partial derivative df/dk; see Equation (1) for the expression of f 
dfdk <- function(X, k) return(-X)
#dfdX was defined earlier

# Algorithm parameters
X_init = 0 # Initial condition of X
k_range = c(0.1, 0.2) # Range of parameter k
dk = 0.001 # Step size for parameter k
nmax_cycle = (k_range[2] - k_range[1])/dk + 1 # Maximum number of cycles

results = matrix(NA, nrow = nmax_cycle, ncol = 3) # Create a matrix to store results
cycle = 1
k = 0.1
d = 1

X_new = runsteady(y=X_init,func=derivs_k_deSolve, parms=c(k,d))$y  # Obtain initial steady-state X from ODE simulation
results[cycle,] = c(k, X_new, -sign(dfdX(X_new, k)))

while((k - k_range[1]) * (k - k_range[2]) <= 0) {   # Check if k is in the range of [k_min, k_max]
  slope = -dfdk(X_new, k)/dfdX(X_new, k)  # Compute the slope of the bifurcation curve (Equation 4)
  # in this implementation, slope can be infinity near a bifurcation point
  k = k + dk
  X_init = X_new + dk * slope
  
  X_new = find_root_Newton(X=X_init, func=derivs_k, dfunc=dfdX, X_range = c(0, 800), k = k) # Correction using Newton's method
  cycle = cycle + 1

  results[cycle,] = c(k, X_new, -sign(dfdX(X_new, k))) # Store results
}

# Plot the bifurcation diagram
plot(NULL, xlab=parse(text="k (Minute^{-1})"), ylab="Xs (nM)", xlim=c(0.09, 0.21), ylim=c(0,600))
points(results[,1], results[,2], pch = 1, cex = 0.3, col = 1)
legend("topright", inset=0.02, legend = c("Stable", "Unstable"), col=1:2, lty=1, cex=0.8)
```

We can see that the algorithm works very well until it reaches to a bifurcation point, where the slope is infinity. It is also a little bit cumbersome to control the direction to move (the same slope can corresponds to two different directions). Thus, we only get a part of the bifurcation curve. 

## An improved continuation method using arc length

To improve the method, we describe the bifurcation curve as the function of arc length $s$, instead of the control parameter $k$. Previously we aim to find $X(k)$, but here we will find $X(s)$ and $k(s)$.

<center> ![Figure 1](./extra/data/02E/fig1.png){width=50%} </center>
<br/>

\begin{equation}
  \Delta s^2 = \Delta k^2 + \Delta X^2 \\
  \Delta X = h \Delta k
\end{equation}

Therefore, we get

\begin{equation}
\begin{cases} \Delta k = \pm \frac{1}{\sqrt{1 + h^2}} \Delta s \\
              \Delta X = h \Delta k \end{cases} \tag{5}
\end{equation}

,where $h(X,k) = \frac{dX}{dk}$ can be computed according to Equation (2). In this case, even when $h$ is infinity, $\Delta k$ and $\Delta X$ are small enough. The choice of $\pm$ in Equation (5) would depend on which direction we want to go. Here, we set $(\Delta k, \Delta X)$ to be in the same direction as that in the previous step.

``` {r}
# Algorithm parameters
X_init = 0 # Initial condition of X
k_range = c(0.1, 0.2) # Range of parameter k
ds = 0.3    # Step size for the arc length
nmax_cycle = 10000 # Maximum number of cycles

results = matrix(NA, nrow = nmax_cycle, ncol = 3)  # Create a matrix to store results
cycle = 1
k = 0.1
d = 1
step_k_previous = 1   # initial step_k is positive
step_X_previous = 0

X_new = runsteady(y=X_init,func=derivs_k_deSolve, parms=c(k,d))$y  # Obtain initial steady-state X from ODE simulation
results[cycle,] = c(k, X_new, -sign(dfdX(X_new, k)))
while(((k - k_range[1]) * (k - k_range[2]) <= 0) & (cycle < nmax_cycle)) {
  h = -dfdk(X_new, k)/dfdX(X_new, k)  
  
  step_k = ds/sqrt(1+h**2)
  step_X = step_k*h
  
  if((step_k_previous * step_k + step_X_previous * step_X) < 0) {  # the direction of change should be the same along the search
    step_k = - step_k
    step_X = - step_X
  }
  step_k_previous = step_k
  step_X_previous = step_X
  
  k = k + step_k
  X_init = X_new + step_X
  
 X_new = find_root_Newton(X=X_init, func=derivs_k, dfunc=dfdX, X_range = c(0, 800), k = k) # Correction using Newton's method
  
  cycle = cycle + 1
  results[cycle,] = c(k, X_new, -sign(dfdX(X_new, k)))
}
results = na.omit(results)

plot(NULL, xlab=parse(text="k (Minute^{-1})"), ylab="Xs (nM)", xlim=c(0.09, 0.21), ylim=c(0,600))
points(results[,1], results[,2], pch = 1, cex = 0.3, col = (3-results[,3])/2)
legend("topright", inset=0.02, legend = c("Stable", "Unstable"), col=1:2, lty=1, cex=0.8)
```

The above implementation works great in this example. It also works reasonably well without the correction method (find_root_Newton). However, numerical continuation may suffer from the divergent issue of Newton's method when the system is near a bifurcation point. In such cases, $f'(X)$ is close to zero. There are methods to alleviate this issue, *.e.g.*, [Halley's method](https://en.wikipedia.org/wiki/Halley%27s_method).
